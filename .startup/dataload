#!/bin/bash

set -x
exec 2> /tmp/debugoutdataload

# download SSTables from s3
curl -O 'https://s3-us-west-1.amazonaws.com/fieldops-public-download/simplegeo_locations_SSTables-DSE5.1.tgz'
sleep 100

# Make sure there are no conflicts in schema
if [dse gremlin-console -e "system.graph('KillrVideo').exists()"]
    then
        dse gremlin-console -e "system.graph('KillrVideo').drop();"
fi

# download and unpack the CSV for graph

dse gremlin-console -e schema.groovy

# extract SSTables to data directory
if [ `hostname` == 'node0' ]
    then
        cqlsh -f cql_schema.cql node0
        pushd /mnt/ephemeral/cassandra/data/simplegeo/locations*; tar -zxvf /tmp/SDDemos/simplegeo_locations_SSTables-DSE5.1.tgz; nodetool refresh simplegeo locations; popd
elif [ `hostname` == 'node1' ]
    then
        cqlsh -f cql_schema.cql node1
        pushd /var/lib/cassandra/data/simplegeo/locations*; tar -zxvf /tmp/SDDemos/simplegeo_locations_SSTables-DSE5.1.tgz; nodetool refresh simplegeo locations; popd
fi
sleep 60

# setup graph data
# dse fs "mkdir /data"
# dse fs "mkdir /data/fraud"
# dse fs "put PS_20174392719_1491204439457_log.csv /data/fraud/transactions.csv"
# dse spark-submit preprocess_data.py
# dse spark-submit pyspark_loader.py

# Repair data
nodetool repair
sleep 60
nodetool upgradesstables
sleep 300
if [ `hostname` == 'node0' ]
    then
        ssh node1 nodetool repair
        sleep 300
        ssh node2 nodetool repair
        sleep 60
        ssh node1 nodetool upgradesstables
        ssh node2 nodetool upgradesstables
elif [ `hostname` == 'node1' ]
    then

        ssh node2 nodetool repair
        sleep 300
        ssh node3 nodetool repair
        sleep 60
        ssh node2 nodetool upgradesstables
        ssh node3 nodetool upgradesstables
fi

# create core and reindex
  dsetool create_core simplegeo.locations schema=schema.xml solrconfig=solrconfig.xml reindex=true distributed=true

# Cleanup
rm -f /tmp/SDDemos/simplegeo_locations_SSTables-DSE5.1.tgz
# rm -f /tmp/SDDemos/put PS_20174392719_1491204439457_log.csv

mkdir /tmp/SDDemos/backup
# pushd /tmp/SDDemos/backup; curl -L -o fraud_graph.tar https://www.dropbox.com/s/qqnzptho9mnlbez/fraud_graph.tar?dl=0; tar -zxvf fraud_graph.tar; popd

pushd /tmp/SDDemos/backup; wget -O fraud_graph.tar https://www.dropbox.com/s/qqnzptho9mnlbez/fraud_graph.tar?dl=0; tar -zxvf fraud_graph.tar; popd


# Name of opscenter backup
TAG=

# get cluster configs
#CLUSTERNAME = curl http://127.0.0.1:8888/cluster-configs | awk '{print $1}'
#echo $CLUSTERNAME


CLUSTERNAME = Cluster_1

curl http://127.0.0.1:8888/Cluster_1/backups | awk '{print $1}'
curl http://127.0.0.1:8888/Cluster_1/backups/graphs/


# get list of all backups pertaining to the graph
# KEYSPACESARRAY = curl http://127.0.0.1:8888/{ClusterName}/backups/graphs/$TAG

#for i in "${KEYSPACESARRAY[@]}"
#do
#   :
#   curl -X POST
#    http://127.0.0.1:8888/$CLUSTERNAME/backups/restore/$TAG/$i
#    -d '{
#      "throttle": 10,
#      "column-families: ["users", "dates"],
#      "truncate": true
#    }'
#done


